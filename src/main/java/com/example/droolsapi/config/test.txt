from pyspark.sql import functions as F

raw = (spark.read.format("snowflake")
       .options(**snowflake_options)
       .option("query", """
         SELECT INDV_ID, AGE, ELEM_NBR, MEM_NAME, ELEM_SUP,
                GRACE_PERIOD, CONTINUITY,
                EFFECTIVE_DATE, MAX_END_DATE, FINAL_END_DATE, MIN_EFF_DATE,
                ELEM_DT_2
         FROM ELEMENT_DATA_TABLE_KIS
       """)
       .load())

# Derived columns only when relevant
is_pharm = (F.col("MEM_NAME") == "INDV_ELEMENTS_PHARM")
has_p2   = F.col("ELEM_SUP").isNotNull() & F.col("ELEM_SUP").startswith("PHARM 2") & (F.length("ELEM_SUP") > 18)
pdc_slice = F.when(is_pharm & has_p2, F.substring("ELEM_SUP", 16, 3))
raw = raw.withColumn("CONTINUOUS_PERIOD", F.col("GRACE_PERIOD")) \
         .withColumn("E_PDC_NUMERATOR_IN_DAYS",
                     F.when(pdc_slice.isNotNull(), F.regexp_replace(pdc_slice, r"[^0-9-]", "").cast("int"))) \
         .withColumn("ADJUSTED_FINAL_DATE",
                     F.when((F.col("CONTINUITY")=="365D_Continuous") &
                            F.col("EFFECTIVE_DATE").isNotNull() & F.col("MAX_END_DATE").isNotNull() &
                            (F.col("EFFECTIVE_DATE") > F.col("MAX_END_DATE")) &
                            F.col("FINAL_END_DATE").isNotNull() & F.col("MIN_EFF_DATE").isNotNull(),
                            F.datediff("FINAL_END_DATE","MIN_EFF_DATE"))) \
         .withColumn("IS_ELEM_DT_2X_DAYS",
                     F.when((F.col("MEM_NAME")=="INDV_ELEMENTS_ADJ") & (F.col("ELEM_NBR").isin(2575,2576)) &
                            F.col("ELEM_DT_2").isNotNull(),
                            F.datediff(F.date_sub(F.current_date(),43), F.to_date("ELEM_DT_2"))))

# Pick ONE pharm per INDV_ID (no Window)
pharm_pick = (raw.filter(is_pharm & (F.col("ELEM_NBR")==2563) & (F.col("E_PDC_NUMERATOR_IN_DAYS")>=210))
                .groupBy("INDV_ID")
                .agg(F.max(F.struct(
                        F.col("ELEM_SUP").startswith("PHARM 2").cast("int").alias("is_p2"),
                        F.length("ELEM_SUP").alias("len_sup"),
                        F.col("ELEM_SUP").alias("pharm_elem_sup")
                    )).alias("mx"))
                .select("INDV_ID", F.col("mx.pharm_elem_sup").alias("PHARM_ELEM_SUP")))

# Aggregate reusable features (single shuffle)
feat = (raw.groupBy("INDV_ID").agg(
          F.max(F.when((F.col("AGE")>=6)&(F.col("AGE")<12),1).otherwise(0)).alias("age_6_12_exists"),
          F.max(F.when(is_pharm & (F.col("ELEM_NBR")==2563) & (F.col("E_PDC_NUMERATOR_IN_DAYS")>=210),1).otherwise(0)).alias("pharm_exists"),
          F.max(F.when(((F.col("CONTINUOUS_PERIOD")>=320)&(F.col("CONTINUITY")=="365D_Continuous")) |
                       ((F.col("ADJUSTED_FINAL_DATE")>=320)&(F.col("CONTINUITY")=="365D_Continuous")),1).otherwise(0)).alias("has_continuity_gate"),
          F.max(F.when((F.col("ELEM_NBR")==3488)&(F.col("MEM_NAME")=="INDV_ELEMENTS_ATTR_EG"),1).otherwise(0)).alias("forbid_3488_attr_eg"),
          F.max(F.when((F.col("MEM_NAME")=="INDV_ELEMENTS_ADJ")&(F.col("ELEM_NBR").isin(2575,2576))&
                       (F.col("IS_ELEM_DT_2X_DAYS")>=0)&(F.col("IS_ELEM_DT_2X_DAYS")<=365),1).otherwise(0)).alias("forbid_adj_window"),
          F.max(F.when((F.col("MEM_NAME")=="INDV_ELEMENTS_ATTR_EG")&(F.col("ELEM_NBR").isin(3496,3159,3103)),1).otherwise(0)).alias("forbid_attr_eg_set")
       ))

features = feat.join(pharm_pick, "INDV_ID", "left") \
               .withColumn("run_date", F.current_date())

# Write once; reuse for many rules
(features
 .write.mode("overwrite")  # or "append" with partitionBy
 .format("delta")
 .partitionBy("run_date")
 .saveAsTable("feature_store.features_indv"))









from pyspark.sql import functions as F

feat = spark.table("feature_store.features_indv").where("run_date = current_date()")

# Evaluate ADHD and DIMAST0051 (example)
rules = {
  "DIMAST0051": ( (F.col("has_3018_ATTR_EG")==1) & (F.col("has_1125_EBM")==1) & (F.col("has_complex_A")==1) & (F.col("forbid_3019")==0) ),
  "TPOBEH001":  ( (F.col("age_6_12_exists")==1) & (F.col("pharm_exists")==1) & (F.col("has_continuity_gate")==1) &
                  (F.col("forbid_3488_attr_eg")==0) & (F.col("forbid_adj_window")==0) & (F.col("forbid_attr_eg_set")==0) )
}
# Build the ADHD THEN output off PHARM_ELEM_SUP only for those that pass
