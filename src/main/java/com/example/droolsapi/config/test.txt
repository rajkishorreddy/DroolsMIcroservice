// ===== 1. Pull ALL rows for just those 2 members into driver memory =====
// (srcDF already filtered to WHERE INDV_ID IN (...))
val testFactsLocal: Seq[CommonDataObject.CommonDataModel] =
  srcDF.collect().toSeq.map(toModel)

println(s"[LOCAL DEBUG] total rows from Snowflake for these INDV_IDs = ${testFactsLocal.size}")

// ===== 2. Group manually by INDV_ID (on driver, no Spark executors) =====
val byMember: Map[Long, Seq[CommonDataObject.CommonDataModel]] =
  testFactsLocal
    .flatMap { m =>
      Option(m.getIndv_id()).map(_.longValue()).map(id => (id, m))
    }
    .groupBy(_._1)
    .mapValues(_.map(_._2))

println(s"[LOCAL DEBUG] num members in this batch = ${byMember.size}")
println(s"[LOCAL DEBUG] members = ${byMember.keys.mkString(",")}")

// ===== 3. Helper to build Drools session, run facts, capture inserts =====
case class OutRow(
  INDV_ID: Long,
  RULE_NUM: String,
  RULE_FLAG: Boolean,
  IS_ACTIVE: String
)

def runRulesForOneMember_localDebug(
  indvId: Long,
  facts: Seq[CommonDataObject.CommonDataModel]
): Seq[OutRow] = {

  println(s"ðŸ”¥ Running Drools for INDV_ID=${indvId} with ${facts.size} facts")

  // fresh stateless session ON DRIVER
  val sess: org.kie.api.runtime.StatelessKieSession =
    buildSessionFromBundle(ruleBundleBC.value)

  // make a global result map (like before)
  val resultMap = new java.util.HashMap[String,Object]()
  sess.setGlobal("result", resultMap)

  // convert scala Seq -> java.util.List[Object] for Drools
  val factObjects = new java.util.ArrayList[Object]()
  facts.foreach(f => factObjects.add(f.asInstanceOf[Object]))

  // 1) insert member facts
  sess.execute(factObjects)

  // 2) now query back inserted CommonDataResultSet rows
  import org.kie.api.runtime.ClassObjectFilter
  val emptyList = new java.util.ArrayList[Object]()
  val droolsResultObjects: java.util.List[_] =
    sess.execute(
      emptyList,
      new ClassObjectFilter(classOf[CommonDataObject.CommonDataResultSet])
    )

  println(s"    ðŸ”Ž Drools returned ${droolsResultObjects.size()} CommonDataResultSet rows")

  // 3) map those inserts -> OutRow
  import scala.collection.JavaConverters._
  val outs: Seq[OutRow] = droolsResultObjects.asScala.toSeq.collect {
    case r: CommonDataObject.CommonDataResultSet =>
      val ruleNum = Option(r.getStatus()).getOrElse("NA")
      OutRow(
        INDV_ID   = indvId,
        RULE_NUM  = ruleNum,
        RULE_FLAG = true,
        IS_ACTIVE = "Y"
      )
  }

  println(s"    âœ… outs for ${indvId} => ${outs.mkString(",")}")
  outs
}

// ===== 4. Run Drools per INDV_ID locally and flatten =====
val allOutRowsLocal: Seq[OutRow] =
  byMember.toSeq.flatMap { case (id, memberFacts) =>
    runRulesForOneMember_localDebug(id, memberFacts)
  }

println(s"[LOCAL DEBUG] TOTAL RESULT ROWS = ${allOutRowsLocal.size}")
allOutRowsLocal.foreach(r => println(s"RESULT => $r"))

// ===== 5. Turn into DF with AUDIT_CREATE_DT just like final pipeline =====
val finalLocalDF =
  spark.createDataFrame(allOutRowsLocal)
    .withColumn("AUDIT_CREAT_DT", current_timestamp())

println("[LOCAL DEBUG] finalLocalDF preview:")
finalLocalDF.show(false)
