from pyspark.sql import functions as F

# 1. Read data from Snowflake into Spark
# NOTE: update options for your Snowflake connection (sfUrl, sfUser, etc.)
snowflake_options = {
    "sfUrl":        "<your_account>.snowflakecomputing.com",
    "sfUser":       "<user>",
    "sfPassword":   "<password>",
    "sfDatabase":   "<DB_NAME>",
    "sfSchema":     "<SCHEMA_NAME>",
    "sfWarehouse":  "<WAREHOUSE_NAME>",
    "sfRole":       "<ROLE_NAME>",
}

source_table = "ELEMENT_DATA_TABLE_KIS"  # change if needed

df = (
    spark.read.format("snowflake")
    .options(**snowflake_options)
    .option("dbtable", source_table)
    .load()
)

# We assume df has columns:
# INDV_ID, AGE, ELEM_NBR, MEM_NAME, ELEM_QTY

# 2. Build boolean flags per INDV_ID for each rule condition

df_flags = (
    df.groupBy("INDV_ID")
    .agg(

        # Condition A:
        # age between 5 and 85 inclusive
        # elem_nbr == 3018 AND mem_name == "INDV_ELEMENTS_ATTR_EG"
        F.max(
            F.when(
                (F.col("AGE") >= 5) &
                (F.col("AGE") <= 85) &
                (F.col("ELEM_NBR") == 3018) &
                (F.col("MEM_NAME") == F.lit("INDV_ELEMENTS_ATTR_EG")),
                F.lit(1)
            ).otherwise(F.lit(0))
        ).alias("has_main_age_attr_eg"),

        # Condition B:
        # elem_nbr == 1125 AND mem_name == "INDV_ELEMENTS_EBM"
        F.max(
            F.when(
                (F.col("ELEM_NBR") == 1125) &
                (F.col("MEM_NAME") == F.lit("INDV_ELEMENTS_EBM")),
                F.lit(1)
            ).otherwise(F.lit(0))
        ).alias("has_ebm_1125"),

        # Condition C (ANY of these 4 subconditions):
        # 1) (elem_nbr == 3153 && mem_name == "INDV_ELEMENTS_ATTR_EG")
        # 2) (elem_nbr == 1166 && elem_qty >= 6.0 && mem_name == "INDV_ELEMENTS_ATTR")
        # 3) (elem_nbr == 1021 && mem_name == "INDV_ELEMENTS_ADJ")
        # 4) (elem_nbr == 1022 && mem_name == "INDV_ELEMENTS_PREADJ")
        F.max(
            F.when(
                (
                    ((F.col("ELEM_NBR") == 3153) &
                     (F.col("MEM_NAME") == F.lit("INDV_ELEMENTS_ATTR_EG")))
                    |
                    ((F.col("ELEM_NBR") == 1166) &
                     (F.col("ELEM_QTY") >= 6.0) &
                     (F.col("MEM_NAME") == F.lit("INDV_ELEMENTS_ATTR")))
                    |
                    ((F.col("ELEM_NBR") == 1021) &
                     (F.col("MEM_NAME") == F.lit("INDV_ELEMENTS_ADJ")))
                    |
                    ((F.col("ELEM_NBR") == 1022) &
                     (F.col("MEM_NAME") == F.lit("INDV_ELEMENTS_PREADJ")))
                ),
                F.lit(1)
            ).otherwise(F.lit(0))
        ).alias("has_any_complex_condition"),

        # Condition D (must NOT exist):
        # NOT (elem_nbr == 3019 AND mem_name == "INDV_ELEMENTS_ATTR_EG")
        # We'll mark if the 'forbidden' combo EXISTS
        F.max(
            F.when(
                (F.col("ELEM_NBR") == 3019) &
                (F.col("MEM_NAME") == F.lit("INDV_ELEMENTS_ATTR_EG")),
                F.lit(1)
            ).otherwise(F.lit(0))
        ).alias("has_forbidden_3019_attr_eg")
    )
)

# 3. Apply the rule:
# We only keep INDV_IDs that satisfy:
# has_main_age_attr_eg == 1
# has_ebm_1125 == 1
# has_any_complex_condition == 1
# has_forbidden_3019_attr_eg == 0   (since NOT exists)

qualified_individuals = (
    df_flags
    .filter(
        (F.col("has_main_age_attr_eg") == 1) &
        (F.col("has_ebm_1125") == 1) &
        (F.col("has_any_complex_condition") == 1) &
        (F.col("has_forbidden_3019_attr_eg") == 0)
    )
    .select(
        F.col("INDV_ID"),
        F.lit("DIMAST0051").alias("STATUS")
    )
)

# 4. Show result
qualified_individuals.show(50, truncate=False)

# If you later want to write back into Snowflake:
# (for now you said just status + indv_id so I'm not inserting)
# qualified_individuals.write.format("snowflake") \
#     .options(**snowflake_options) \
#     .option("dbtable", "STREAMLIT_RESULTS_KIS") \
#     .mode("append") \
#     .save()
