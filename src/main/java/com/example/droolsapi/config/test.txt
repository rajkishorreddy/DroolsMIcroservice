from pyspark.sql import functions as F

# Source DF: project to only needed columns
df_src = df.select("INDV_ID", "AGE", "ELEM_NBR", "MEM_NAME", "ELEM_QTY")

# === 1) Build reusable features in ONE aggregation ===
df_feat = (
    df_src.groupBy("INDV_ID")
    .agg(
        # Feature names are intentionally readable and reusable across rules

        # Base combos
        F.max(F.when((F.col("AGE") >= 5) & (F.col("AGE") <= 85) &
                     (F.col("ELEM_NBR") == 3018) &
                     (F.col("MEM_NAME") == "INDV_ELEMENTS_ATTR_EG"), 1).otherwise(0)).alias("has_3018_ATTR_EG_age_5_85"),

        F.max(F.when((F.col("ELEM_NBR") == 1125) &
                     (F.col("MEM_NAME") == "INDV_ELEMENTS_EBM"), 1).otherwise(0)).alias("has_1125_EBM"),

        F.max(F.when(
            ((F.col("ELEM_NBR") == 3153) & (F.col("MEM_NAME") == "INDV_ELEMENTS_ATTR_EG")) |
            ((F.col("ELEM_NBR") == 1166) & (F.col("ELEM_QTY") >= 6.0) & (F.col("MEM_NAME") == "INDV_ELEMENTS_ATTR")) |
            ((F.col("ELEM_NBR") == 1021) & (F.col("MEM_NAME") == "INDV_ELEMENTS_ADJ")) |
            ((F.col("ELEM_NBR") == 1022) & (F.col("MEM_NAME") == "INDV_ELEMENTS_PREADJ")),
            1).otherwise(0)
        ).alias("has_any_complex_condition_A"),

        F.max(F.when((F.col("ELEM_NBR") == 3019) &
                     (F.col("MEM_NAME") == "INDV_ELEMENTS_ATTR_EG"), 1).otherwise(0)).alias("has_3019_ATTR_EG_forbidden"),

        # (Add more features here that other rules need; keep them generic & reusable)
    )
)

# === 2) Define rules as boolean expressions over features ===
# Rule DIMAST0051 (AsthmaRule) from earlier
rule_DIMAST0051 = (
    (F.col("has_3018_ATTR_EG_age_5_85") == 1) &
    (F.col("has_1125_EBM") == 1) &
    (F.col("has_any_complex_condition_A") == 1) &
    (F.col("has_3019_ATTR_EG_forbidden") == 0)
)

# Example of a second rule (placeholder; tweak as needed)
# Say DIMXYZ0002 requires 1125_EBM and NOT 1022_PREADJ
feat_has_1022_PREADJ = F.col("has_any_complex_condition_A")  # example reuse; replace with its own feature if needed
rule_DIMXYZ0002 = (
    (F.col("has_1125_EBM") == 1) &
    (feat_has_1022_PREADJ == 0)  # replace with correct feature(s)
)

# Registry of rules: name -> expression
rules = {
    "DIMAST0051": rule_DIMAST0051,
    # "DIMXYZ0002": rule_DIMXYZ0002,
    # Add more rules hereâ€¦
}

# === 3) Evaluate all rules at once (wide) ===
rule_cols = [
    F.when(expr, F.lit(1)).otherwise(F.lit(0)).alias(rule_name)
    for rule_name, expr in rules.items()
]

df_rules_wide = df_feat.select("INDV_ID", *rule_cols)

# === 4) Unpivot to long format: (INDV_ID, STATUS) only for passed rules ===
# Turn columns into an array of (rule, value), explode, then filter value==1
pairs = F.array(*[
    F.struct(F.lit(rule_name).alias("STATUS"), F.col(rule_name).alias("value"))
    for rule_name in rules.keys()
])

df_rules_long = (
    df_rules_wide
    .select("INDV_ID", F.explode(pairs).alias("p"))
    .select("INDV_ID", F.col("p.STATUS").alias("STATUS"), F.col("p.value").alias("value"))
    .filter(F.col("value") == 1)
    .select("INDV_ID", "STATUS")
)

# df_rules_long now has multiple rows per INDV_ID if the individual passes multiple rules
df_rules_long.show(100, truncate=False)
