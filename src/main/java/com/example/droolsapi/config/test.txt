// ======================================================
// ðŸ§© Drools per-INDV_ID execution on Databricks
// ======================================================
import org.apache.spark.sql.Row
import scala.collection.JavaConverters._
import org.kie.api.KieServices
import org.kie.api.builder.{KieBuilder, Message}
import org.kie.api.io.ResourceType
import org.kie.internal.io.ResourceFactory
import org.kie.api.runtime.{KieSession}
import org.kie.api.runtime.ClassObjectFilter
import CommonDataObject._
import java.sql.Date

// ---------- Build KieBase once ----------
def buildKieBaseFromDbfs(dir: String) = {
  val ks = KieServices.Factory.get
  val kfs = ks.newKieFileSystem()

  dbutils.fs.ls(dir)
    .filter(_.name.toLowerCase.endsWith(".drl"))
    .foreach { f =>
      val body = dbutils.fs.head(f.path)
      kfs.write(
        ResourceFactory
          .newByteArrayResource(body.getBytes("UTF-8"))
          .setSourcePath(f.path) // âœ… required to avoid runtime exception
          .setResourceType(ResourceType.DRL)
      )
    }

  val kbuilder: KieBuilder = ks.newKieBuilder(kfs).buildAll()
  val results = kbuilder.getResults
  if (results.hasMessages(Message.Level.ERROR)) {
    val errs = results.getMessages(Message.Level.ERROR).asScala.mkString("\n")
    throw new IllegalStateException(s"DROOLS BUILD ERRORS:\n$errs")
  }
  ks.newKieContainer(ks.getRepository.getDefaultReleaseId).getKieBase
}

// ---------- Fire rules for one INDV ----------
def fireRulesForIndv(kbase: org.kie.api.KieBase, indvId: Long, facts: Seq[CommonDataModel]) = {
  val sess: KieSession = kbase.newKieSession()
  try {
    facts.foreach(sess.insert)
    val fired = sess.fireAllRules()
    val resultObjs = sess
      .getObjects(new ClassObjectFilter(classOf[CommonDataResultSet]))
      .asScala
      .collect { case r: CommonDataResultSet => r }
      .toSeq
    println(s"ðŸ”¥ INDV_ID=$indvId | fired=$fired | results=${resultObjs.size}")
    resultObjs.map(_.getStatus()).distinct.map(st => (indvId, st))
  } finally sess.dispose()
}

// ---------- Main driver ----------
val kbase = buildKieBaseFromDbfs("dbfs:/FileStore/rules")

// assuming you already have memberFacts from Snowflake query earlier
// (Seq[CommonDataModel])
val grouped = memberFacts.groupBy(f => Option(f.getIndv_id).map(_.toLong).getOrElse(-1L))

println(s"Grouping complete: ${grouped.size} INDV_IDs")

val allResults = grouped.toSeq.flatMap { case (id, facts) =>
  fireRulesForIndv(kbase, id, facts)
}.toSeq

// ---------- Show results ----------
import spark.implicits._
val resultsDF = allResults.toDF("INDV_ID", "RULE_STATUS")

println("âœ… Final results per INDV_ID:")
resultsDF.show(truncate=false)
