%scala
import org.kie.api.KieServices
import org.kie.api.builder.{KieBuilder, Message, Results}
import org.kie.internal.io.ResourceFactory
import org.kie.api.runtime.KieSession
import org.kie.api.runtime.ClassObjectFilter
import org.kie.api.KieBase // âœ… correct package for KieBase
import java.nio.charset.StandardCharsets
import scala.collection.JavaConverters._
import java.sql.Date
import CommonDataObject.{CommonDataModel, CommonDataResultSet}

// ---------- Build KieBase once ----------
def buildKieBaseFromFolder(dirDbfs: String): KieBase = {
  val ks  = KieServices.Factory.get
  val kfs = ks.newKieFileSystem()
  val dirLocal = dirDbfs.replace("dbfs:/", "/dbfs/")
  val drlFiles = Option(new java.io.File(dirLocal).listFiles)
    .getOrElse(Array.empty)
    .filter(f => f.isFile && f.getName.endsWith(".drl"))

  println(s"ðŸ§© Found DRLs: ${drlFiles.map(_.getName).mkString(", ")}")

  drlFiles.foreach { f =>
    val body = scala.io.Source.fromFile(f, "UTF-8").mkString
    kfs.write(
      ResourceFactory
        .newByteArrayResource(body.getBytes(StandardCharsets.UTF_8))
        .setSourcePath(s"rules/${f.getName}")
    )
  }

  val kb: KieBuilder = ks.newKieBuilder(kfs).buildAll()
  val res: Results   = kb.getResults
  if (res.hasMessages(Message.Level.ERROR)) {
    println("âŒ DRL build errors:")
    res.getMessages(Message.Level.ERROR).forEach(m => println("  " + m))
    throw new IllegalStateException("DRL compile failed")
  }

  ks.newKieContainer(ks.getRepository.getDefaultReleaseId).getKieBase
}

def d(s: String): java.sql.Date = Date.valueOf(s)

case class Out(indvId: Long, status: String, active: String)

// ---------- Fire rules for one indv ----------
def fireForOne(kbase: KieBase, indvId: Long, facts: Seq[CommonDataModel]): Seq[Out] = {
  val ksession: KieSession = kbase.newKieSession()
  try {
    facts.foreach(ksession.insert)
    val fired = ksession.fireAllRules()
    println(s"ðŸ”¥ INDV $indvId -> fired $fired")
    ksession.getObjects(new ClassObjectFilter(classOf[CommonDataResultSet]))
      .asScala
      .collect { case r: CommonDataResultSet =>
        Out(indvId, Option(r.getStatus).getOrElse("NA"), "Y")
      }.toSeq
  } finally ksession.dispose()
}

// ---------- Run partitioned by indv ----------
def runPartitionedByIndv(facts: Seq[CommonDataModel], rulesDir: String = "dbfs:/FileStore/rules"): Seq[Out] = {
  val kbase = buildKieBaseFromFolder(rulesDir)
  val groups = facts.groupBy(f => Option(f.getIndv_id).map(_.longValue).getOrElse(-1L))
  groups.toSeq.sortBy(_._1).flatMap { case (indvId, fs) => fireForOne(kbase, indvId, fs) }
}

// ---------- Demo facts ----------
val indv1 = 12345: java.lang.Integer
val indv2 = 99999: java.lang.Integer

def factSetForAdolescent(indv: java.lang.Integer): Seq[CommonDataModel] = {
  val a = new CommonDataModel(); a.setIndv_id(indv); a.setDob(d("2013-08-15"))
  val b = new CommonDataModel(); b.setIndv_id(indv); b.setContinuity("365D_Continuous")
  b.setEffective_date(d("2024-01-01")); b.setMax_end_date(d("2023-12-31"))
  b.setMin_eff_date(d("2023-01-01")); b.setFinal_end_date(d("2024-12-31"))
  b.setGrace_period(400: java.lang.Integer)
  val c = new CommonDataModel(); c.setIndv_id(indv)
  c.setElem_nbr(3327: java.lang.Integer); c.setMem_name("INDV_ELEMENTS_ATTR_EG")
  c.setContinuity("365D_Continuous")
  Seq(a,b,c)
}

def factSetForAsthma(indv: java.lang.Integer): Seq[CommonDataModel] = {
  val p = new CommonDataModel(); p.setIndv_id(indv); p.setAge(25: java.lang.Integer)
  p.setElem_nbr(3018: java.lang.Integer); p.setMem_name("INDV_ELEMENTS_ATTR_EG")
  val q = new CommonDataModel(); q.setIndv_id(indv)
  q.setElem_nbr(1125: java.lang.Integer); q.setMem_name("INDV_ELEMENTS_EBM")
  val r = new CommonDataModel(); r.setIndv_id(indv)
  r.setElem_nbr(1021: java.lang.Integer); r.setMem_name("INDV_ELEMENTS_ADJ")
  Seq(p,q,r)
}

// Combine both membersâ€™ facts
val allFacts = factSetForAdolescent(indv1) ++ factSetForAsthma(indv1) ++ factSetForAsthma(indv2)

// ---------- Run ----------
val outs = runPartitionedByIndv(allFacts, "dbfs:/FileStore/rules")

println("\nðŸš€ RESULTS (partitioned by INDV_ID)")
outs.groupBy(_.indvId).toSeq.sortBy(_._1).foreach { case (id, rows) =>
  println(s"INDV $id -> ${rows.map(o => s"${o.status}").mkString(", ")}")
}
println(s"\nâœ… TOTAL ROWS: ${outs.size}")
