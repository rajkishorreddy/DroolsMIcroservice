from pyspark.sql import functions as F
from pyspark.sql.window import Window

# -------- 0) Load full table (you said: select * from table) --------
df = (
    spark.read.format("snowflake")
    .options(**snowflake_options)
    .option("dbtable", "ELEMENT_DATA_TABLE_KIS")   # change if needed
    .load()
)

# -------- 1) Derived columns to mirror Java getters --------

# 1a) getContinuousPeriod(): use GRACE_PERIOD as CONTINUOUS_PERIOD
if "GRACE_PERIOD" in df.columns and "CONTINUOUS_PERIOD" not in df.columns:
    df = df.withColumnRenamed("GRACE_PERIOD", "CONTINUOUS_PERIOD")

# 1b) ePdcNumeratorInDays (from elem_sup when startsWith "PHARM 2")
# Java substr(15,18) [0-based, end-exclusive] -> Spark substring(16, 3)
pdc_base = F.when(
    (F.col("ELEM_SUP").isNotNull()) &
    (F.length("ELEM_SUP") > 18) &
    (F.substring("ELEM_SUP", 1, 7) == F.lit("PHARM 2")),
    F.substring("ELEM_SUP", 16, 3)
)
pdc_digits = F.regexp_replace(pdc_base, r"[^0-9-]", "")
df = df.withColumn(
    "E_PDC_NUMERATOR_IN_DAYS",
    F.when(F.length(pdc_digits) > 0, pdc_digits.cast("int"))
)

# 1c) adjustedFinalDate
df = df.withColumn(
    "ADJUSTED_FINAL_DATE",
    F.when(
        F.col("EFFECTIVE_DATE").isNotNull() &
        F.col("MAX_END_DATE").isNotNull() &
        (F.col("EFFECTIVE_DATE") > F.col("MAX_END_DATE")) &
        F.col("FINAL_END_DATE").isNotNull() &
        F.col("MIN_EFF_DATE").isNotNull(),
        F.datediff(F.col("FINAL_END_DATE"), F.col("MIN_EFF_DATE"))
    )
)

# 1d) isElemDt2XDays (days between elem_dt_2 and today-43)
today_minus_43 = F.date_sub(F.current_date(), 43)
df = df.withColumn(
    "IS_ELEM_DT_2X_DAYS",
    F.when(F.col("ELEM_DT_2").isNotNull(), F.datediff(today_minus_43, F.to_date("ELEM_DT_2")))
)

# -------- 2) Feature flags per INDV_ID (EXISTS / NOT EXISTS) --------
feat = (
    df.groupBy("INDV_ID").agg(

        # $cdm : age in [6,12)
        F.max(F.when((F.col("AGE") >= 6) & (F.col("AGE") < 12), 1).otherwise(0)).alias("age_6_12_exists"),

        # $pharm : elem_nbr=2563, mem_name="INDV_ELEMENTS_PHARM", ePdcNumeratorInDays>=210
        F.max(F.when(
            (F.col("ELEM_NBR") == 2563) &
            (F.col("MEM_NAME") == "INDV_ELEMENTS_PHARM") &
            (F.col("E_PDC_NUMERATOR_IN_DAYS") >= 210),
            1).otherwise(0)
        ).alias("pharm_exists"),

        # exists( (continuousPeriod>=320 && continuity=="365D_Continuous") ||
        #         (adjustedFinalDate>=320 && continuity=="365D_Continuous") )
        F.max(F.when(
            ((F.col("CONTINUOUS_PERIOD") >= 320) & (F.col("CONTINUITY") == "365D_Continuous")) |
            ((F.col("ADJUSTED_FINAL_DATE") >= 320) & (F.col("CONTINUITY") == "365D_Continuous")),
            1).otherwise(0)
        ).alias("has_continuity_gate"),

        # not( elem_nbr==3488 && ATTR_EG )
        F.max(F.when(
            (F.col("ELEM_NBR") == 3488) & (F.col("MEM_NAME") == "INDV_ELEMENTS_ATTR_EG"),
            1).otherwise(0)
        ).alias("has_forbidden_3488_attr_eg"),

        # not( (2575 && ADJ && 0<=isElemDt2XDays<=365) || (2576 && ADJ && 0<=...<=365) )
        F.max(F.when(
            (
                ((F.col("ELEM_NBR") == 2575) & (F.col("MEM_NAME") == "INDV_ELEMENTS_ADJ")) |
                ((F.col("ELEM_NBR") == 2576) & (F.col("MEM_NAME") == "INDV_ELEMENTS_ADJ"))
            ) &
            (F.col("IS_ELEM_DT_2X_DAYS") >= 0) &
            (F.col("IS_ELEM_DT_2X_DAYS") <= 365),
            1).otherwise(0)
        ).alias("has_forbidden_adj_window"),

        # not( 3496 || 3159 || 3103  with ATTR_EG )
        F.max(F.when(
            (F.col("MEM_NAME") == "INDV_ELEMENTS_ATTR_EG") &
            (F.col("ELEM_NBR").isin(3496, 3159, 3103)),
            1).otherwise(0)
        ).alias("has_forbidden_attr_eg_set")
    )
)

# -------- 3) Pick ONE $pharm row per INDV_ID for THEN logic --------
pharm_rows = df.filter(
    (F.col("ELEM_NBR") == 2563) &
    (F.col("MEM_NAME") == "INDV_ELEMENTS_PHARM") &
    (F.col("E_PDC_NUMERATOR_IN_DAYS") >= 210)
).select("INDV_ID", "ELEM_SUP")

# Prefer startsWith("PHARM 2"), tie-break by longest ELEM_SUP
pharm_ranked = (pharm_rows
                .withColumn("is_pharm2", F.col("ELEM_SUP").startswith("PHARM 2").cast("int"))
                .withColumn("len_sup", F.length("ELEM_SUP")))
w = Window.partitionBy("INDV_ID").orderBy(F.col("is_pharm2").desc(), F.col("len_sup").desc())
pharm_one = (pharm_ranked
             .withColumn("rn", F.row_number().over(w))
             .filter("rn=1")
             .drop("rn", "is_pharm2", "len_sup"))

# -------- 4) THEN block (exact branches with "M" / "B") --------
startsWithPharm2 = F.col("ELEM_SUP").isNotNull() & F.col("ELEM_SUP").startswith("PHARM 2")
len_ge_152 = (F.length("ELEM_SUP") >= 152)
len_ge_131 = (F.length("ELEM_SUP") >= 131)

# Java substring(a,b) -> Spark substring(a+1, b-a)
# (93,103)->(94,10) ; (115,125)->(116,10) ; (114,115)->(115,1) ; (130,131)->(131,1)
s93_103  = F.substring("ELEM_SUP", 94, 10)
s115_125 = F.substring("ELEM_SUP", 116, 10)
flag115  = F.when(len_ge_131, F.substring("ELEM_SUP", 115, 1))
flag131  = F.when(len_ge_131, F.substring("ELEM_SUP", 131, 1))

to_num = lambda s: F.when(F.length(F.regexp_replace(s, r"[^0-9-]", "")) > 0,
                          F.regexp_replace(s, r"[^0-9-]", "").cast("double"))

# score1 (len>=152)
score1Desc = F.when(len_ge_152, F.lit("RXMD"))
score1Nbr  = F.when(len_ge_152, to_num(s93_103))

# score2/score3 (flags "M" / "B")
score2Desc = F.when(flag115 == F.lit("M"), F.lit("MXRXMD")) \
              .when((flag115.isNotNull()) & (flag115 != F.lit("M")) & (flag115 != F.lit("B")) & (flag131 == F.lit("M")), F.lit("MXRXMD"))
score2Nbr  = F.when(flag115 == F.lit("M"), to_num(s93_103)) \
              .when((flag115.isNotNull()) & (flag115 != F.lit("M")) & (flag115 != F.lit("B")) & (flag131 == F.lit("M")), to_num(s115_125))

score3Desc = F.when(flag115 == F.lit("B"), F.lit("BHRXMD")) \
              .when((flag115.isNotNull()) & (flag115 != F.lit("M")) & (flag115 != F.lit("B")) & (flag131 == F.lit("B")), F.lit("BHRXMD"))
score3Nbr  = F.when(flag115 == F.lit("B"), to_num(s93_103)) \
              .when((flag115.isNotNull()) & (flag115 != F.lit("M")) & (flag115 != F.lit("B")) & (flag131 == F.lit("B")), to_num(s115_125))

then_cols = (
    pharm_one
    .withColumn("startsWithPharm2", startsWithPharm2)
    .withColumn("score1Desc", score1Desc).withColumn("score1Nbr", score1Nbr)
    .withColumn("score2Desc", score2Desc).withColumn("score2Nbr", score2Nbr)
    .withColumn("score3Desc", score3Desc).withColumn("score3Nbr", score3Nbr)
    .select("INDV_ID","startsWithPharm2","score1Desc","score1Nbr","score2Desc","score2Nbr","score3Desc","score3Nbr")
)

# -------- 5) Rule gates (all must pass) --------
rule_pass = (
    (F.col("age_6_12_exists") == 1) &
    (F.col("pharm_exists") == 1) &
    (F.col("has_continuity_gate") == 1) &
    (F.col("has_forbidden_3488_attr_eg") == 0) &
    (F.col("has_forbidden_adj_window") == 0) &
    (F.col("has_forbidden_attr_eg_set") == 0)
)

# -------- 6) Build STATUS and emit --------
joined = feat.join(then_cols, "INDV_ID", "left")

# print "null" when any score field is null
s = lambda c: F.when(F.col(c).isNotNull(), F.col(c).cast("string")).otherwise(F.lit("null"))

status = F.concat_ws(
    "",
    F.lit("TPOBEH001 ; "),
    s("score1Desc"), F.lit(" ; "), s("score1Nbr"),  F.lit(" ; "),
    s("score2Desc"), F.lit(" ; "), s("score2Nbr"),  F.lit(" ; "),
    s("score3Desc"), F.lit(" ; "), s("score3Nbr")
)

result = (
    joined
    .filter(rule_pass & F.col("startsWithPharm2"))   # THEN guard: elem_sup startsWith("PHARM 2")
    .select("INDV_ID", status.alias("STATUS"))
)

result.show(50, truncate=False)
