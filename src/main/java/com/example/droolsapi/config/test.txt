import org.apache.spark.sql.functions._

// ====== STEP 2: Load small batch from Snowflake ======
val df = spark.read
  .format("snowflake")
  .options(sfOptions)
  .option("query", "SELECT * FROM ELEMENT_DATA_TABLE_KIS LIMIT 10000") // small batch for test
  .load()

// ====== Inspect schema & sample ======
df.printSchema()
df.select("INDV_ID", "ELEM_NBR", "MEM_NAME").show(20, false)

// ====== STEP 3: Partition by INDV_ID ======
val grouped = df.groupBy("INDV_ID").count()
println(s"âœ… Total unique INDV_IDs: ${grouped.count()}")

// Show a few partitions
grouped.orderBy(desc("count")).show(10)
